Training of deberta with 1e-6 training data is finished with error 
DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
!

DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

--------------------------------------------------
Training of deberta with 1e-5 training data is finished with error 
DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
!

DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

--------------------------------------------------
Training of deberta with 5e-5 training data is finished with error 
DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
!

DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

--------------------------------------------------
Training of deberta with 5e-6 training data is finished with error 
DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
!

DebertaV2Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

--------------------------------------------------
Training of deberta with 5e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 5e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 5e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 5e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 5e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 5e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-5 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-6 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-06 training data is finished with error 'input text'!
'input text'
--------------------------------------------------
Training of deberta with 5e-06 training data is finished with error 'input text'!
'input text'
--------------------------------------------------
Training of deberta with 1e-05 training data is finished with error 'input text'!
'input text'
--------------------------------------------------
Training of deberta with 5e-05 training data is finished with error 'input text'!
'input text'
--------------------------------------------------
Training of deberta with 1e-06 training data is finished with error CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)!
CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
--------------------------------------------------
Training of deberta with 5e-06 training data is finished with error CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)!
CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
--------------------------------------------------
Training of deberta with 1e-05 training data is finished with error CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)!
CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
--------------------------------------------------
Training of deberta with 5e-05 training data is finished with error CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)!
CUDA out of memory. Tried to allocate 510.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 51.12 MiB is free. Including non-PyTorch memory, this process has 31.69 GiB memory in use. Of the allocated memory 30.12 GiB is allocated by PyTorch, and 676.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
--------------------------------------------------
Training of deberta with 5e-7 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
Training of deberta with 1e-7 training data is finished with error '<=' not supported between instances of 'float' and 'str'!
'<=' not supported between instances of 'float' and 'str'
--------------------------------------------------
